{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkcyan> First implementation of a few MCMC algorithms</font>\n",
    "#### <font color=darkorange>Metropolis-Hastings and MALA </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings for better clarity (may not be the best thing to do)...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autograd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38296/3513231162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autograd'"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Required packages\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "# package which differentiates standard Python and Numpy code\n",
    "from autograd import grad\n",
    "# to get progress bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Bayesian setting, a parameter $x$ is embedded with a prior distribution $\\pi$ and the observations are given by a probabilistic model:\n",
    "\n",
    "$$\n",
    "Y\\sim \\ell(\\cdot|x)\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "The inference is then based on the posterior distribution:\n",
    "$$\n",
    "\\pi(x|Y) = \\frac{\\pi(x)\\ell(Y|x)}{\\int\\pi(u)\\ell(Y|u)\\mathrm{d} u}\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "In most cases the normalizing constant is not tractable:\n",
    "$$\n",
    "\\pi(x|Y) \\propto \\pi(x)\\ell(Y|x)\\,.\n",
    "$$\n",
    "\n",
    "``Markov chain Monte Carlo (MCMC) algorithms`` provide solutions to sample from posterior distributions. ``Hamiltonian Monte Carlo (HMC)`` is a MCMC algorithm that uses gradient information to scale better to higher dimensions. It is used by software like [PyMC3](https://pymc.io/) and [Stan](https://mc-stan.org/). \n",
    "\n",
    "Some references on MCMC...\n",
    "- **Douc R., Moulines E. and Stoffer D.**, Nonlinear time series: theory, methods and applications with R example, 2014, Chapman \\& Hall.\n",
    "- **Michael Betancourt, [A Conceptual Introduction to Hamiltonian Monte Carlo](https://arxiv.org/abs/1701.02434)** A thorough, readable reference that is the main source here\n",
    "\n",
    "In the following cells, we drop $Y$ from the notations and consider a target distribution written $\\pi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> A few simple models </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the target density is written $\\pi$. We define below two examples of target densities $\\pi$ which will be used to assess the efficiency of the proposed MCMC algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function returning the opposite of the log probability density of </font>\n",
    "    \n",
    "<font color=darkred>    i) a Gaussian random variable with mean mu and covariance matrix sigma; </font>\n",
    "    \n",
    "<font color=darkred>    ii) a mixture of probability density functions. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2236789780.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38296/2236789780.py\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    det       = # To be completed\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def multi_gauss(mu, sigma):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    mu: mean of the Gaussian distribution\n",
    "    sigma: covariance matrix of the Gaussian distribution\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    logp: opposite of the loglikelihood\n",
    "    \"\"\"\n",
    "\n",
    "    def logp(x):\n",
    "        k   = mu.shape[0]\n",
    "        cst       = k * np.log(2 * np.pi)\n",
    "        det       = # To be completed\n",
    "        quad_term = # To be completed\n",
    "        return (cst +  det + quad_term) * 0.5\n",
    "    \n",
    "    return logp\n",
    "\n",
    "def mixture(log_prob, weights):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    log_prob: opposite of the likelihood of each term\n",
    "    weights: weights of the components of the mixture\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    logp: opposite of the loglikelihood of the mixture\n",
    "    \"\"\"\n",
    "    \n",
    "    def logp(x):\n",
    "        likelihood = 0\n",
    "        for j in range(np.size(weights)):\n",
    "            log_marginal = # To be completed\n",
    "            likelihood   = # To be completed\n",
    "        \n",
    "        return -np.log(likelihood)\n",
    "\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38296/203009934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnb_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mxplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrid_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0myplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrid_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mXplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "grid_lim = 6\n",
    "# grid on which the target pdf is displayed\n",
    "grid_plot = (-grid_lim, grid_lim, -grid_lim, grid_lim)\n",
    "# coordinates chosen on this grid\n",
    "nb_points = 100\n",
    "\n",
    "xplot = np.linspace(-grid_lim, grid_lim, nb_points)\n",
    "yplot = np.linspace(-grid_lim, grid_lim, nb_points)\n",
    "Xplot, Yplot = np.meshgrid(xplot, yplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Display a target density defined as a mixture of 2-dimensional Gaussian distributions. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = 2*np.ones(2)\n",
    "cov1 = np.array([[1., 0.5],\n",
    "                [0.5, 1.]])\n",
    "mu2 = -mu1\n",
    "cov2 = np.array([[1., -0.1],\n",
    "                [-0.1, 1.]])\n",
    "\n",
    "mu3 = np.array([-1.5, 2.2])\n",
    "cov3 = 0.8 * np.eye(2)\n",
    "\n",
    "mu4 = np.array([2.5, -4.2])\n",
    "cov4 = 0.5 * np.eye(2)\n",
    "\n",
    "log_p = # To be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.title('Multi-modal target distribution')\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_p(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "plt.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=darkcyan> Metropolis-Hastings algorithm </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Objective target density:`` $\\pi(x)$.\n",
    "\n",
    "``Instrumental transition density:`` $q(x,y)$.\n",
    "\n",
    "At each iteration $k\\geqslant 0$, generate $Z_{k+1} \\sim q(X_k,\\cdot)$.\n",
    "\n",
    "Set $X_{k+1} = Z_{k+1}$ with probability $\\alpha(X_k,Z_{k+1})$ and  $X_{k+1} = X_k$ with probability $1-\\alpha(X_k,Z_{k+1})$, where \n",
    "\n",
    "$$\n",
    "\\alpha(x,y) = 1\\wedge\\frac{\\pi(y)}{\\pi(x)}\\frac{q(y,x)}{q(x,y)}\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function which returns samples from Metropolis-Hastings algorithm with Gaussian proposal density.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HM_monte_carlo(n_samples, log_prob, initial_state, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    n_samples: number of samples to return\n",
    "    log_prob: opposite of the loglikelihood to sample from\n",
    "    initial_state: initial sample\n",
    "    step_size: standard deviation of the proposed moves\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    samples: samples from the MCMC algorithm\n",
    "    accepted: array of 0 and 1 to display which proposed moves have been accepted\n",
    "    \"\"\"\n",
    "    initial_state = np.array(initial_state)\n",
    "    \n",
    "    samples  = [initial_state]\n",
    "    accepted = []\n",
    "\n",
    "    size = (n_samples,) + initial_state.shape[:1]\n",
    "    \n",
    "    # random variable to sample proposed moves\n",
    "    epsilon = st.norm(0, 1).rvs(size)\n",
    "    \n",
    "    for noise in tqdm(epsilon):\n",
    "        \n",
    "        q_new = # To be completed\n",
    "       \n",
    "        # acceptance rate\n",
    "        old_log_p = # To be completed\n",
    "        new_log_p = # To be completed\n",
    "        \n",
    "        if np.log(np.random.rand()) < # To be completed\n",
    "            samples.append(q_new)\n",
    "            accepted.append(True)\n",
    "        else:\n",
    "            samples.append(np.copy(samples[-1]))\n",
    "            accepted.append(False)\n",
    "\n",
    "    return (np.array(samples[1:]),np.array(accepted),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=darkcyan> Metropolis Adjusted Langevin algorithm (MALA) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Objective target density:`` $\\pi(x)$.\n",
    "\n",
    "At each iteration $k\\geqslant 0$, generate $Z_{k+1} \\sim X_k + \\frac{\\sigma^2}{2}\\nabla\\log\\pi(X_k|Y) + \\sigma \\varepsilon_{k+1}$.\n",
    "\n",
    "Set $X_{k+1} = Z_{k+1}$ with probability $\\alpha(X_k,Z_{k+1})$ and  $X_{k+1} = X_k$ with probability $1-\\alpha(X_k,Z_{k+1})$, where \n",
    "\n",
    "$$\n",
    "\\alpha(x,y) = 1\\wedge\\frac{\\pi(y)}{\\pi(x)}\\frac{q(y,x)}{q(x,y)}\\,,\n",
    "$$\n",
    "\n",
    "where $q(x,y)$ is the Gaussian pdf with mean $x + \\frac{\\sigma^2}{2}\\nabla\\log\\pi(x|Y)$ and variance $\\sigma^2 I_d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function which returns samples from MALA algorithm.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MALA_monte_carlo(n_samples, log_prob, initial_state, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    n_samples: number of samples to return\n",
    "    log_prob: opposite of the loglikelihood to sample from\n",
    "    initial_state: initial sample\n",
    "    step_size: standard deviation of the proposed moves\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    samples: samples from the MCMC algorithm\n",
    "    accepted: array of 0 and 1 to display which proposed moves have been accepted\n",
    "    \"\"\"\n",
    "    initial_state = np.array(initial_state)\n",
    "\n",
    "    gradV = grad(log_prob)\n",
    "\n",
    "    samples  = [initial_state]\n",
    "    accepted = []\n",
    "\n",
    "    size = (n_samples,) + initial_state.shape[:1]\n",
    "    \n",
    "    # random variable to sample proposed moves\n",
    "    epsilon = st.norm(0, 1).rvs(size)\n",
    "    \n",
    "    for noise in tqdm(epsilon):\n",
    "        \n",
    "        grad_new = # To be completed\n",
    "        mean_new = # To be completed\n",
    "        \n",
    "        q_new    = # To be completed\n",
    "       \n",
    "        grad_y   = # To be completed\n",
    "        mean_y   = # To be completed\n",
    "        \n",
    "        # acceptance rate\n",
    "        old_log_p = # To be completed\n",
    "        new_log_p = # To be completed\n",
    "        \n",
    "        if np.log(np.random.rand()) < # To be completed:\n",
    "            samples.append(q_new)\n",
    "            accepted.append(True)\n",
    "        else:\n",
    "            samples.append(np.copy(samples[-1]))\n",
    "            accepted.append(False)\n",
    "\n",
    "    return (np.array(samples[1:]),np.array(accepted),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> A few samples </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Run both algorithms to produce Markov chains with length n_samples.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_HM, accepted_HM = HM_monte_carlo(n_samples, log_p, np.random.randn(2), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_Mala, accepted_Mala = MALA_monte_carlo(n_samples, log_p, np.random.randn(2), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.title('Multi-modal target distribution')\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_p(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "plt.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "plt.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6, label = 'Metropolis-Hastings')\n",
    "plt.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6, label = 'MALA')\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> Parameters tuning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Display the mean acceptance rate for both algorithms</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Provide an estimate of the mean of the target distribution for both algorithms</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Analyze the influence of the step-size for both algorithms (in particular on the mean acceptance rates)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Provide a comparison between the empirical distributions from the target and for both algorithms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
