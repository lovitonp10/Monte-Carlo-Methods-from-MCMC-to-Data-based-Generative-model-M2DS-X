{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkcyan> First implementation of a few MCMC algorithms</font>\n",
    "#### <font color=darkorange>Metropolis-Hastings and MALA </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings for better clarity (may not be the best thing to do)...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Required packages\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "# package which differentiates standard Python and Numpy code\n",
    "from autograd import grad\n",
    "# to get progress bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Bayesian setting, a parameter $x$ is embedded with a prior distribution $\\pi$ and the observations are given by a probabilistic model:\n",
    "\n",
    "$$\n",
    "Y\\sim \\ell(\\cdot|x)\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "The inference is then based on the posterior distribution:\n",
    "$$\n",
    "\\pi(x|Y) = \\frac{\\pi(x)\\ell(Y|x)}{\\int\\pi(u)\\ell(Y|u)\\mathrm{d} u}\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "In most cases the normalizing constant is not tractable:\n",
    "$$\n",
    "\\pi(x|Y) \\propto \\pi(x)\\ell(Y|x)\\,.\n",
    "$$\n",
    "\n",
    "``Markov chain Monte Carlo (MCMC) algorithms`` provide solutions to sample from posterior distributions. ``Hamiltonian Monte Carlo (HMC)`` is a MCMC algorithm that uses gradient information to scale better to higher dimensions. It is used by software like [PyMC3](https://pymc.io/) and [Stan](https://mc-stan.org/). \n",
    "\n",
    "Some references on MCMC...\n",
    "- **Douc R., Moulines E. and Stoffer D.**, Nonlinear time series: theory, methods and applications with R example, 2014, Chapman \\& Hall.\n",
    "- **Michael Betancourt, [A Conceptual Introduction to Hamiltonian Monte Carlo](https://arxiv.org/abs/1701.02434)** A thorough, readable reference that is the main source here\n",
    "\n",
    "In the following cells, we drop $Y$ from the notations and consider a target distribution written $\\pi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> A few simple models </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the target density is written $\\pi$. We define below two examples of target densities $\\pi$ which will be used to assess the efficiency of the proposed MCMC algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function returning the opposite of the log probability density of </font>\n",
    "    \n",
    "<font color=darkred>    i) a Gaussian random variable with mean mu and covariance matrix sigma; </font>\n",
    "    \n",
    "<font color=darkred>    ii) a mixture of probability density functions. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_gauss(mu, sigma):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    mu: mean of the Gaussian distribution\n",
    "    sigma: covariance matrix of the Gaussian distribution\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    logp: opposite of the loglikelihood\n",
    "    \"\"\"\n",
    "\n",
    "    def logp(x):\n",
    "        k   = mu.shape[0]\n",
    "        cst       = k * np.log(2 * np.pi)\n",
    "        det       = np.log(np.linalg.det(sigma))\n",
    "        quad_term = np.dot(np.dot((x - mu).T, np.linalg.inv(sigma)), x - mu)\n",
    "        return (cst +  det + quad_term) * 0.5\n",
    "    \n",
    "    return logp\n",
    "\n",
    "def mixture(log_prob, weights):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    log_prob: opposite of the likelihood of each term\n",
    "    weights: weights of the components of the mixture\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    logp: opposite of the loglikelihood of the mixture\n",
    "    \"\"\"\n",
    "    \n",
    "    def logp(x):\n",
    "        likelihood = 0\n",
    "        for j in range(np.size(weights)):\n",
    "            log_marginal = -log_prob[j](x)\n",
    "            likelihood   = likelihood + weights[j]*np.exp(log_marginal)\n",
    "        \n",
    "        return -np.log(likelihood)\n",
    "\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lim = 6\n",
    "# grid on which the target pdf is displayed\n",
    "grid_plot = (-grid_lim, grid_lim, -grid_lim, grid_lim)\n",
    "# coordinates chosen on this grid\n",
    "nb_points = 100\n",
    "\n",
    "xplot = np.linspace(-grid_lim, grid_lim, nb_points)\n",
    "yplot = np.linspace(-grid_lim, grid_lim, nb_points)\n",
    "Xplot, Yplot = np.meshgrid(xplot, yplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Display a target density defined as a mixture of 2-dimensional Gaussian distributions. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = 2*np.ones(2)\n",
    "cov1 = np.array([[1., 0.5],\n",
    "                [0.5, 1.]])\n",
    "mu2 = -mu1\n",
    "cov2 = np.array([[1., -0.1],\n",
    "                [-0.1, 1.]])\n",
    "\n",
    "mu3 = np.array([-1.5, 2.2])\n",
    "cov3 = 0.8 * np.eye(2)\n",
    "\n",
    "mu4 = np.array([2.5, -4.2])\n",
    "cov4 = 0.5 * np.eye(2)\n",
    "\n",
    "log_p = mixture([multi_gauss(mu1, cov1), multi_gauss(mu2, cov2), multi_gauss(mu3, cov3), multi_gauss(mu4, cov4)], [0.25, 0.35, 0.3,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.title('Multi-modal target distribution')\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_p(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "plt.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='upper')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=darkcyan> Metropolis-Hastings algorithm </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Objective target density:`` $\\pi(x)$.\n",
    "\n",
    "``Instrumental transition density:`` $q(x,y)$.\n",
    "\n",
    "At each iteration $k\\geqslant 0$, generate $Z_{k+1} \\sim q(X_k,\\cdot)$.\n",
    "\n",
    "Set $X_{k+1} = Z_{k+1}$ with probability $\\alpha(X_k,Z_{k+1})$ and  $X_{k+1} = X_k$ with probability $1-\\alpha(X_k,Z_{k+1})$, where \n",
    "\n",
    "$$\n",
    "\\alpha(x,y) = 1\\wedge\\frac{\\pi(y)}{\\pi(x)}\\frac{q(y,x)}{q(x,y)}\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function which returns samples from Metropolis-Hastings algorithm with Gaussian proposal density.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HM_monte_carlo(n_samples, log_prob, initial_state, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    n_samples: number of samples to return\n",
    "    log_prob: opposite of the loglikelihood to sample from\n",
    "    initial_state: initial sample\n",
    "    step_size: standard deviation of the proposed moves\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    samples: samples from the MCMC algorithm\n",
    "    accepted: array of 0 and 1 to display which proposed moves have been accepted\n",
    "    \"\"\"\n",
    "    initial_state = np.array(initial_state)\n",
    "    \n",
    "    samples  = [initial_state]\n",
    "    accepted = []\n",
    "\n",
    "    size = (n_samples,) + initial_state.shape[:1]\n",
    "    \n",
    "    # random variable to sample proposed moves\n",
    "    epsilon = st.norm(0, 1).rvs(size)\n",
    "    \n",
    "    for noise in tqdm(epsilon):\n",
    "        \n",
    "        q_new = samples[-1] + step_size*noise\n",
    "       \n",
    "        # acceptance rate\n",
    "        old_log_p = log_prob(samples[-1]) \n",
    "        new_log_p = log_prob(q_new) \n",
    "        \n",
    "        if np.log(np.random.rand()) < old_log_p - new_log_p:\n",
    "            samples.append(q_new)\n",
    "            accepted.append(True)\n",
    "        else:\n",
    "            samples.append(np.copy(samples[-1]))\n",
    "            accepted.append(False)\n",
    "\n",
    "    return (np.array(samples[1:]),np.array(accepted),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=darkcyan> Metropolis Adjusted Langevin algorithm (MALA) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Objective target density:`` $\\pi(x)$.\n",
    "\n",
    "At each iteration $k\\geqslant 0$, generate $Z_{k+1} \\sim X_k + \\frac{\\sigma^2}{2}\\nabla\\log\\pi(X_k|Y) + \\sigma \\varepsilon_{k+1}$.\n",
    "\n",
    "Set $X_{k+1} = Z_{k+1}$ with probability $\\alpha(X_k,Z_{k+1})$ and  $X_{k+1} = X_k$ with probability $1-\\alpha(X_k,Z_{k+1})$, where \n",
    "\n",
    "$$\n",
    "\\alpha(x,y) = 1\\wedge\\frac{\\pi(y)}{\\pi(x)}\\frac{q(y,x)}{q(x,y)}\\,,\n",
    "$$\n",
    "\n",
    "where $q(x,y)$ is the Gaussian pdf with mean $x + \\frac{\\sigma^2}{2}\\nabla\\log\\pi(x)$ and variance $\\sigma^2 I_d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function which returns samples from MALA algorithm.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MALA_monte_carlo(n_samples, log_prob, initial_state, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    n_samples: number of samples to return\n",
    "    log_prob: opposite of the loglikelihood to sample from\n",
    "    initial_state: initial sample\n",
    "    step_size: standard deviation of the proposed moves\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    samples: samples from the MCMC algorithm\n",
    "    accepted: array of 0 and 1 to display which proposed moves have been accepted\n",
    "    \"\"\"\n",
    "    initial_state = np.array(initial_state)\n",
    "\n",
    "    gradV = grad(log_prob)\n",
    "\n",
    "    samples  = [initial_state]\n",
    "    accepted = []\n",
    "\n",
    "    size = (n_samples,) + initial_state.shape[:1]\n",
    "    \n",
    "    # random variable to sample proposed moves\n",
    "    epsilon = st.norm(0, 1).rvs(size)\n",
    "    \n",
    "    for noise in tqdm(epsilon):\n",
    "        \n",
    "        grad_new = gradV(samples[-1])\n",
    "        mean_new = samples[-1] - 0.5*step_size*step_size*grad_new\n",
    "        \n",
    "        q_new    = mean_new + step_size*noise\n",
    "       \n",
    "        grad_y   = gradV(q_new)\n",
    "        mean_y   = q_new - 0.5*step_size*step_size*grad_y\n",
    "        \n",
    "        # acceptance rate\n",
    "        old_log_p = log_prob(samples[-1]) + 0.5*np.dot(q_new-mean_new,q_new-mean_new)/(step_size**2)\n",
    "        new_log_p = log_prob(q_new) + 0.5*np.dot(samples[-1]-mean_y,samples[-1]-mean_y)/(step_size**2)\n",
    "        \n",
    "        if np.log(np.random.rand()) < old_log_p - new_log_p:\n",
    "            samples.append(q_new)\n",
    "            accepted.append(True)\n",
    "        else:\n",
    "            samples.append(np.copy(samples[-1]))\n",
    "            accepted.append(False)\n",
    "\n",
    "    return (np.array(samples[1:]),np.array(accepted),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> A few samples </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Run both algorithms to produce Markov chains with length n_samples.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:08<00:00, 2270.54it/s]\n"
     ]
    }
   ],
   "source": [
    "samples_HM, accepted_HM = HM_monte_carlo(n_samples, log_p, np.random.randn(2), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 10158/20000 [00:48<00:47, 207.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38582/604273685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_Mala\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_Mala\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMALA_monte_carlo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38582/3378995129.py\u001b[0m in \u001b[0;36mMALA_monte_carlo\u001b[0;34m(n_samples, log_prob, initial_state, step_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mq_new\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mmean_new\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mgrad_y\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mgradV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mmean_y\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mq_new\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38582/2476918535.py\u001b[0m in \u001b[0;36mlogp\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mlog_marginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mlikelihood\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_marginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f0/q7nn178n5cldx0lvl6yvbbn40000gn/T/ipykernel_38582/2476918535.py\u001b[0m in \u001b[0;36mlogp\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcst\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdet\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mquad_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcst\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mdet\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquad_term\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/numpy/numpy_boxes.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__neg__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value, fun, args, kwargs, parent_argnums, parents)\u001b[0m\n\u001b[1;32m     34\u001b[0m             raise NotImplementedError(\"VJP of {} wrt argnums {} not defined\"\n\u001b[1;32m     35\u001b[0m                                       .format(fun_name, parent_argnums))\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjpmaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_argnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp_argnums\u001b[0;34m(argnums, ans, args, kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 raise NotImplementedError(\n\u001b[1;32m     65\u001b[0m                     \"VJP of {} wrt argnum 0 not defined\".format(fun.__name__))\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjpfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ans, x, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m defvjp(anp.multiply,    lambda ans, x, y : unbroadcast_f(x, lambda g: y * g),\n\u001b[1;32m     35\u001b[0m                         lambda ans, x, y : unbroadcast_f(y, lambda g: x * g))\n\u001b[0;32m---> 36\u001b[0;31m defvjp(anp.subtract,    lambda ans, x, y : unbroadcast_f(x, lambda g: g),\n\u001b[0m\u001b[1;32m     37\u001b[0m                         lambda ans, x, y : unbroadcast_f(y, lambda g: -g))\n\u001b[1;32m     38\u001b[0m defvjp(anp.divide,      lambda ans, x, y : unbroadcast_f(x, lambda g:   g / y),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36munbroadcast_f\u001b[0;34m(target, f)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munbroadcast_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m     \u001b[0mtarget_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnotrace_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples_Mala, accepted_Mala = MALA_monte_carlo(n_samples, log_p, np.random.randn(2), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.title('Multi-modal target distribution')\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_p(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "plt.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "plt.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.3, label = 'Metropolis-Hastings')\n",
    "plt.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.3, label = 'MALA')\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> Parameters tuning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Display the mean acceptance rate for both algorithms</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Provide an estimate of the mean of the target distribution for both algorithms</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Analyze the influence of the step-size for both algorithms (in particular on the mean acceptance rates)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Provide a comparison between the empirical distributions from the target and for both algorithms</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=darkcyan> Hamiltonian Monte Carlo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> Framework </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unknown  parameters are gathered into a _position_ variable, usually written $\\mathbf{q}$. \n",
    "An auxiliary variable, called ``momentum`` and written $\\mathbf{p}$, is introduced to define the extended joint probability distribution \n",
    "\n",
    "$$\n",
    "\\pi(\\mathbf{q}, \\mathbf{p}) =  \\pi(\\mathbf{q}) \\pi(\\mathbf{p} | \\mathbf{q})\\,,\n",
    "$$\n",
    "\n",
    "In most cases $\\pi(\\mathbf{p} | \\mathbf{q})$ is the probability density of a Gaussian random variable with mean $0$ and variance $M$.\n",
    "\n",
    "The ``Hamiltonian`` associated with this model is  $H(\\mathbf{q}, \\mathbf{p}) = -\\log \\pi(\\mathbf{q}, \\mathbf{p})$ so that\n",
    "\n",
    "$$\n",
    "H(\\mathbf{q}, \\mathbf{p}) = -\\log \\pi(\\mathbf{p} | \\mathbf{q}) - \\log \\pi(\\mathbf{q}) = K(\\mathbf{p}, \\mathbf{q}) + V(\\mathbf{q}|Y)\\,,\n",
    "$$\n",
    "\n",
    "where $K(\\mathbf{p}, \\mathbf{q})$ is called the _kinetic energy_, and $V(\\mathbf{q})$ is called the _potential energy_.\n",
    "\n",
    "The dynamics of the system $(\\mathbf{q}, \\mathbf{p})$ is assumed to follow _Hamilton's equations_:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d} \\mathbf{q}}{\\mathrm{d}t} = \\frac{\\partial H}{\\partial \\mathbf{p}} = \\frac{\\partial K}{\\partial \\mathbf{p}} + \\frac{\\partial V}{\\partial \\mathbf{p}}\\\\\n",
    "\\frac{\\mathrm{d} \\mathbf{p}}{\\mathrm{d}t} = -\\frac{\\partial H}{\\partial \\mathbf{q}}= -\\frac{\\partial K}{\\partial \\mathbf{q}} + \\frac{\\partial V}{\\partial \\mathbf{q}}\n",
    "$$\n",
    "\n",
    "\n",
    "When $\\pi(\\mathbf{p} | \\mathbf{q},Y)$ is the probability density of a Gaussian random variable with mean $0$ and variance $M$, this yields\n",
    "\n",
    "$$\n",
    "K(\\mathbf{p}, \\mathbf{q}) = \\frac{1}{2}\\mathbf{p}^T M^{-1}\\mathbf{p} + \\log |M| + \\text{C},\n",
    "$$\n",
    "\n",
    "In the specific case of $M=I$,  \n",
    "$$\n",
    "K(\\mathbf{p}, \\mathbf{q}) = \\frac{1}{2}\\mathbf{p}^T \\mathbf{p} + \\text{C}\\,,\n",
    "$$\n",
    "\n",
    "so that\n",
    "\n",
    "$$\n",
    "\\frac{\\partial K}{\\partial \\mathbf{p}} = \\mathbf{p} \\quad \\mathrm{and} \\quad \\frac{\\partial K}{\\partial \\mathbf{q}} = \\mathbf{0}\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "Finally,\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d} \\mathbf{q}}{\\mathrm{d}t}  = \\mathbf{p}\\quad \\mathrm{and} \\quad \\frac{\\mathrm{d} \\mathbf{p}}{\\mathrm{d}t} = - \\frac{\\partial V}{\\partial \\mathbf{q}}\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function returning the positions and momemtums of a Euler scheme based interator </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_integrator(q, p, gradientV, T, step):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    q: initial position\n",
    "    p: initial momentum\n",
    "    gradientV: gradient of the velocity\n",
    "    T: time horizon\n",
    "    step: step size to discretize the ODE\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    q, p: last position and last momentum\n",
    "    posisions: sequence of positions produced by the Euler based scheme integrator\n",
    "    momentums: sequence of momentums produced by the Euler based scheme integrator\n",
    "    \"\"\"\n",
    "    \n",
    "    q, p      = np.copy(q), np.copy(p)\n",
    "    pos, moms = [np.copy(q)], [np.copy(p)]\n",
    "\n",
    "    vq = gradientV(q)\n",
    "    nb_steps = int(T / step)\n",
    "    \n",
    "    for it in range(nb_steps):\n",
    "        p = p - step * vq\n",
    "        q = q + step * p  \n",
    "        pos.append(np.copy(q))\n",
    "        vq = gradientV(q)\n",
    "        moms.append(np.copy(p))\n",
    "\n",
    "    return q, -p, np.array(pos), np.array(moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> The Leapfrog integrator </font>\n",
    "The leapfrog integrator may be used to approximate the ordinary differential equations (ODE) $q$ and $p$ are solutions to. \n",
    "\n",
    "It involves updating the momentum `p` a half step, then the position `q` a whole step, and then finish updating `p` the other half of the step.\n",
    "\n",
    "A momentum flip at the end is required to preserve the reversibility of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Write a function returning the positions and momemtums of a leapfrog interator </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leapfrog_integrator(q, p, gradientV, T, step):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    q: initial position\n",
    "    p: initial momentum\n",
    "    gradientV: gradient of the velocity\n",
    "    T: time horizon\n",
    "    step: step size to discretize the ODE\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    q, p: last position and last momentum\n",
    "    posisions: sequence of positions produced by the leapfrog integrator\n",
    "    momentums: sequence of momentums produced by the leapfrog integrator\n",
    "    \"\"\"\n",
    "    \n",
    "    q, p      = np.copy(q), np.copy(p)\n",
    "    pos, moms = [np.copy(q)], [np.copy(p)]\n",
    "\n",
    "    vq = gradientV(q)\n",
    "    nb_steps = int(T / step)\n",
    "    \n",
    "    for it in range(nb_steps):\n",
    "        p = p - 0.5*step * vq \n",
    "        q = q + step * p  \n",
    "        pos.append(np.copy(q))\n",
    "        vq = gradientV(q)\n",
    "        p = p - 0.5*step * vq\n",
    "        moms.append(np.copy(p))\n",
    "\n",
    "    return q, -p, np.array(pos), np.array(moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Illustrate the points proposed by the leapfrog integrator along a trajectory for a 2-dimensional Gaussian distribution. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_density = multi_gauss(np.zeros(2), np.eye(2))\n",
    "gradV = grad(log_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, p = np.random.randn(2, 2)\n",
    "_, _, positions_leap, momentums_leap = leapfrog_integrator(q, p, gradV, 2 * np.pi, 0.1)\n",
    "_, _, positions_euler, momentums_euler = euler_integrator(q, p, gradV, 2 * np.pi, 0.1)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('One trajectory from the integrators - unimodal case')\n",
    "\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_density(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "\n",
    "plt.imshow(Zplot, alpha=0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "plt.plot(positions_leap[:,0], positions_leap[:,1], marker='o', markersize = 1, markeredgecolor='black', label = 'Leapfrog integrator')\n",
    "plt.plot(positions_euler[:,0], positions_euler[:,1], marker='o', markersize = 1, markeredgecolor='orange', label = 'Euler based integrator')\n",
    "plt.tick_params(labelright=True)\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, p = np.random.randn(2, 2)\n",
    "_, _, positions_leap, momentums_leap = leapfrog_integrator(q, p, gradV, 2 * np.pi, 0.5)\n",
    "_, _, positions_euler, momentums_euler = euler_integrator(q, p, gradV, 2 * np.pi, 0.5)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('One trajectory from the integrators - unimodal case')\n",
    "plt.imshow(Zplot, alpha=0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "plt.plot(positions_leap[:,0], positions_leap[:,1], marker='o', markersize = 4, markeredgecolor='black', label = 'Leapfrog integrator')\n",
    "plt.plot(positions_euler[:,0], positions_euler[:,1], marker='o', markersize = 4, markeredgecolor='orange', label = 'Euler based integrator')\n",
    "plt.tick_params(labelright=True)\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('Several trajectories obtained from the leapfrog integrator - unimodal case')\n",
    "positions, momentums = [], []\n",
    "for _ in range(3):\n",
    "    q, p = np.random.randn(2, 2)\n",
    "    _, _, pos, moms = leapfrog_integrator(q, p, gradV, 2 * np.pi, 0.01)\n",
    "    positions.append(pos)\n",
    "    momentums.append(moms)\n",
    "\n",
    "plt.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap = 'Blues', origin = 'top')\n",
    "\n",
    "for idx_traj in range(3):\n",
    "    plt.plot(positions[idx_traj][:,0], positions[idx_traj][:,1], marker='o', markersize = 1, label = 'Trajectory %g'%idx_traj)\n",
    "plt.tick_params(labelright=True)\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Display several trajectories of the leapfrog integrator for a target defined as a mixture of 2-dimensional Gaussian distributions. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = 2*np.ones(2)\n",
    "cov1 = np.array([[1., 0.5],\n",
    "                [0.5, 1.]])\n",
    "mu2 = -mu1\n",
    "cov2 = np.array([[1., -0.1],\n",
    "                [-0.1, 1.]])\n",
    "\n",
    "mu3 = np.array([-1.5, 2.2])\n",
    "cov3 = 0.8 * np.eye(2)\n",
    "\n",
    "logp  = mixture([multi_gauss(mu1, cov1), multi_gauss(mu2, cov2), multi_gauss(mu3, cov3)], [0.25, 0.35, 0.4])\n",
    "gradV = grad(logp)\n",
    "\n",
    "\n",
    "positions, momentums = [], []\n",
    "for it in range(5):\n",
    "    q, p = np.random.randn(2, 2)\n",
    "    _, _, pos, moms = leapfrog_integrator(q, p, gradV, 4 * np.pi, 0.01)\n",
    "    positions.append(pos)\n",
    "    momentums.append(moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('Several trajectories obtained from the leapfrog integrator - multimodal case')\n",
    "\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-logp(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "\n",
    "plt.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap = 'Blues', origin = 'top')\n",
    "\n",
    "for idx_traj in range(5):\n",
    "    plt.plot(positions[idx_traj][:,0], positions[idx_traj][:,1], marker='.', markersize = 1, label = 'Trajectory %g'%idx_traj)\n",
    "plt.tick_params(labelright=True)\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> The Hamiltonian loop </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Use the leapfrog function to write a Hamiltonian loop i.e. a Hamiltonian MCMC with a generic target distribution. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamiltonian_monte_carlo(n_samples, log_prob, initial_position, T = 1, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    n_samples: number of samples to return.\n",
    "    log_prob: opposite of the target log probability.\n",
    "    initial_position: a place to start sampling from.\n",
    "    T: length of leapfrog integration.\n",
    "    step_size: step size of the integration scheme.\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    samples: samples produced by the HMC.\n",
    "    sample_positions: positions obtained by the leapfrog integrator at each time step.\n",
    "    sample_momentums: momentums obtained by the leapfrog integrator at each time step.\n",
    "    accepted: array of 0 and 1 to display which proposed moves have been accepted.\n",
    "    \"\"\"\n",
    "    initial_position = np.array(initial_position)\n",
    "    \n",
    "    gradV = grad(log_prob)\n",
    "\n",
    "    samples = [initial_position]\n",
    "    sample_positions, sample_momentums = [], []\n",
    "    accepted = []\n",
    "\n",
    "    size = (n_samples,) + initial_position.shape[:1]\n",
    "    \n",
    "    # all momentums\n",
    "    momentum = st.norm(0, 1).rvs(size)\n",
    "    \n",
    "    for p0 in tqdm(momentum):\n",
    "        q_new, p_new, positions, momentums = leapfrog_integrator(samples[-1], p0, gradV, 2 * np.random.rand() * T,step_size)\n",
    "        sample_positions.append(positions)\n",
    "        sample_momentums.append(momentums)\n",
    "\n",
    "        # acceptance rate\n",
    "        old_log_p = log_prob(samples[-1]) - np.sum(st.norm(0, 1).logpdf(p0))\n",
    "        new_log_p = log_prob(q_new) - np.sum(st.norm(0, 1).logpdf(p_new))\n",
    "        \n",
    "        if np.log(np.random.rand()) < old_log_p - new_log_p:\n",
    "            samples.append(q_new)\n",
    "            accepted.append(True)\n",
    "        else:\n",
    "            samples.append(np.copy(samples[-1]))\n",
    "            accepted.append(False)\n",
    "\n",
    "    return (np.array(samples[1:]),np.array(sample_positions),np.array(sample_momentums),np.array(accepted),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Display several trajectories of the HMC loop for a Gaussian target distribution </font>\n",
    "\n",
    "<font color=darkred>i) Illustrate the influence of the total length of the leapfrog integrator. </font>\n",
    "\n",
    "<font color=darkred>ii) Illustrate the influence of the step size of the leapfrog integrator. </font>\n",
    "\n",
    "<font color=darkred>iii) Compare the performance with a HM algorithm. </font>\n",
    "\n",
    "<font color=darkred>iv) Compare the performance with a MALA algorithm. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p = multi_gauss(np.zeros(2), np.eye(2))\n",
    "\n",
    "n_samples = 150\n",
    "step_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_T = [1, 5, 10, 15]\n",
    "samples_HMC = []\n",
    "positions_HMC = []\n",
    "momentums_HMC = []\n",
    "\n",
    "for T in all_T:\n",
    "    samples, positions, momentums, accepted = hamiltonian_monte_carlo(n_samples, log_p, np.random.randn(2), T, step_size)\n",
    "    samples_HMC.append(samples)\n",
    "    positions_HMC.append(positions)\n",
    "    momentums_HMC.append(momentums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_HM, accepted_HM = HM_monte_carlo(5*n_samples, log_p, np.random.randn(2), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_Mala, accepted_Mala = MALA_monte_carlo(5*n_samples, log_p, np.random.randn(2), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,14))\n",
    "ax1  = fig.add_subplot(221)\n",
    "ax2  = fig.add_subplot(222) \n",
    "ax3  = fig.add_subplot(223)\n",
    "ax4  = fig.add_subplot(224)\n",
    "ax1.set_title('Length of the leapfrog: %g'%all_T[0])\n",
    "ax2.set_title('Length of the leapfrog: %g'%all_T[1])\n",
    "ax3.set_title('Length of the leapfrog: %g'%all_T[2])\n",
    "ax4.set_title('Length of the leapfrog: %g'%all_T[3])\n",
    "\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_p(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "\n",
    "ax1.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax1.plot(samples_HMC[0][:,0], samples_HMC[0][:,1], '.', color='black', label = 'Hamiltonian')\n",
    "ax1.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6, label = 'Metropolis-Hastings')\n",
    "ax1.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6, label = 'MALA')\n",
    "ax1.grid(True)\n",
    "for i in range(n_samples):\n",
    "    ax1.plot(positions_HMC[0][i][:, 0], positions_HMC[0][i][:, 1], 'k--', lw = 1, alpha = 0.2)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax2.plot(samples_HMC[1][:,0], samples_HMC[1][:,1], '.', color='black')\n",
    "ax2.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6)\n",
    "ax2.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6)\n",
    "ax2.grid(True)\n",
    "for i in range(n_samples):\n",
    "    ax2.plot(positions_HMC[1][i][:, 0], positions_HMC[1][i][:, 1], 'k--', lw = 1, alpha = 0.2)\n",
    "    \n",
    "ax3.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax3.plot(samples_HMC[2][:,0], samples_HMC[2][:,1], '.', color='black')\n",
    "ax3.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6)\n",
    "ax3.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6)\n",
    "ax3.grid(True)\n",
    "for i in range(n_samples):\n",
    "    ax3.plot(positions_HMC[2][i][:, 0], positions_HMC[2][i][:, 1], 'k--', lw = 1, alpha = 0.2)\n",
    "    \n",
    "ax4.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax4.plot(samples_HMC[3][:,0], samples_HMC[3][:,1], '.', color='black')\n",
    "ax4.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6)\n",
    "ax4.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6)\n",
    "ax4.grid(True)\n",
    "for i in range(n_samples):\n",
    "    ax4.plot(positions_HMC[3][i][:, 0], positions_HMC[3][i][:, 1], 'k--', lw = 1, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Display several trajectories of the HMC algorithm for a target defined as a mixture of Gaussian distributions. </font>\n",
    "\n",
    "<font color=darkred>i) Illustrate the influence of the total length of the leapfrog integrator. </font>\n",
    "\n",
    "<font color=darkred>ii) Illustrate the influence of the step size of the leapfrog integrator. </font>\n",
    "\n",
    "<font color=darkred>iii) Compare the performance with a HM algorithm. </font>\n",
    "\n",
    "<font color=darkred>iv) Compare the performance with a MALA algorithm. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = 2*np.ones(2)\n",
    "cov1 = np.array([[1., 0.5],\n",
    "                [0.5, 1.]])\n",
    "mu2 = -mu1\n",
    "cov2 = np.array([[1., -0.1],\n",
    "                [-0.1, 1.]])\n",
    "\n",
    "mu3 = np.array([-1.5, 2.2])\n",
    "cov3 = 0.8 * np.eye(2)\n",
    "\n",
    "mu4 = np.array([2.5, -4.2])\n",
    "cov4 = 0.5 * np.eye(2)\n",
    "\n",
    "log_p = mixture([multi_gauss(mu1, cov1), multi_gauss(mu2, cov2), multi_gauss(mu3, cov3), multi_gauss(mu4, cov4)], [0.25, 0.35, 0.3,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Total length of the leapfrog integrator. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 150\n",
    "step_size = 0.1\n",
    "all_T = [1, 5, 10, 15]\n",
    "samples_HMC = []\n",
    "positions_HMC = []\n",
    "momentums_HMC = []\n",
    "\n",
    "for T in all_T:\n",
    "    samples, positions, momentums, accepted = hamiltonian_monte_carlo(n_samples, log_p, np.random.randn(2), T, step_size)\n",
    "    samples_HMC.append(samples)\n",
    "    positions_HMC.append(positions)\n",
    "    momentums_HMC.append(momentums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_HM, accepted_HM = HM_monte_carlo(5*n_samples, log_p, np.random.randn(2), step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_Mala, accepted_Mala = MALA_monte_carlo(5*n_samples, log_p, np.random.randn(2), step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,14))\n",
    "ax1  = fig.add_subplot(221)\n",
    "ax2  = fig.add_subplot(222) \n",
    "ax3  = fig.add_subplot(223)\n",
    "ax4  = fig.add_subplot(224)\n",
    "ax1.set_title('Length of the leapfrog: %g'%all_T[0])\n",
    "ax2.set_title('Length of the leapfrog: %g'%all_T[1])\n",
    "ax3.set_title('Length of the leapfrog: %g'%all_T[2])\n",
    "ax4.set_title('Length of the leapfrog: %g'%all_T[3])\n",
    "\n",
    "Zplot = np.copy(Xplot)\n",
    "for i in range(nb_points):\n",
    "    for j in range(nb_points):\n",
    "        Zplot[i][j] = np.exp(-log_p(np.array((Xplot[i][j], Yplot[i][j]))))\n",
    "\n",
    "ax1.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax1.plot(samples_HMC[0][:,0], samples_HMC[0][:,1], '.', color='black', label = 'Hamiltonian')\n",
    "ax1.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6, label = 'Metropolis-Hastings')\n",
    "ax1.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6, label = 'MALA')\n",
    "ax1.grid(True)\n",
    "#for i in range(n_samples):\n",
    "#    ax1.plot(positions_HMC[0][i][:, 0], positions_HMC[0][i][:, 1], 'k--', lw = 1, alpha = 0.2)\n",
    "ax1.legend()\n",
    "    \n",
    "ax2.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax2.plot(samples_HMC[1][:,0], samples_HMC[1][:,1], '.', color='black')\n",
    "ax2.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6)\n",
    "ax2.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6)\n",
    "ax2.grid(True)\n",
    "#for i in range(n_samples):\n",
    "#    ax2.plot(positions_HMC[1][i][:, 0], positions_HMC[1][i][:, 1], 'k--', lw = 1, alpha = 0.2)\n",
    "    \n",
    "ax3.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax3.plot(samples_HMC[2][:,0], samples_HMC[2][:,1], '.', color='black')\n",
    "ax3.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6)\n",
    "ax3.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6)\n",
    "ax3.grid(True)\n",
    "#for i in range(n_samples):\n",
    "#    ax3.plot(positions_HMC[2][i][:, 0], positions_HMC[2][i][:, 1], 'k--', lw = 1, alpha = 0.2)\n",
    "    \n",
    "ax4.imshow(Zplot, alpha = 0.9, extent = grid_plot, cmap='Blues', origin='top')\n",
    "ax4.plot(samples_HMC[3][:,0], samples_HMC[3][:,1], '.', color='black')\n",
    "ax4.plot(samples_HM[:,0], samples_HM[:,1], '.', color='orange', alpha = 0.6)\n",
    "ax4.plot(samples_Mala[:,0], samples_Mala[:,1], '.', color='violet', alpha = 0.6)\n",
    "ax4.grid(True)\n",
    "#for i in range(n_samples):\n",
    "#    ax4.plot(positions_HMC[3][i][:, 0], positions_HMC[3][i][:, 1], 'k--', lw = 1, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkorange> Parameters tuning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Analyze the optimal tuning of the HMC parameters: variance matrix of the momentums, step-size, length of the symplectic integration...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
